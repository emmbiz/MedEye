{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xray_image_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNC+LzWmK83LuTPJnlG7VTd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmbiz/MedEye/blob/master/xray_image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ2vjvkOADtK"
      },
      "source": [
        "### Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe34wttm8fXM"
      },
      "source": [
        "# Import necessary packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4GYRZptAUG3"
      },
      "source": [
        "### Create datasets for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v7GIBMxAVWh"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data_folder = '/content/drive/MyDrive/chest-x-ray-data/train_data'\n",
        "\n",
        "print(\"[INFO] loading images...\")\n",
        "data_folder = 'train_data'\n",
        "image_size = (224, 224)\n",
        "data = []\n",
        "labels = []\n",
        "image_paths = list(paths.list_images(data_folder))\n",
        "for image_path in image_paths:\n",
        "    # Load the input image (224x224) and preprocess it\n",
        "    img = load_img(image_path, target_size=image_size)\n",
        "    image = img_to_array(img) / 255.0\n",
        "\n",
        "    # Extract the class label from the filename\n",
        "    label = image_path.split(os.path.sep)[-2]\n",
        "\n",
        "    # Update the data and labels lists respectively\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "\n",
        "# Convert the data and labels to NumPy arrays\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "print(\"[INFO] data: {} images ({:.2f}MB)\".format(len(image_paths), data.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "# Perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "# Show each of the possible class labels\n",
        "print(\"[INFO] class labels:\")\n",
        "for (number, label) in enumerate(lb.classes_):\n",
        "    print(\"{}. {}\".format(number + 1, label))\n",
        "\n",
        "# Partition the data into training and testing splits (80%-20% respectively)\n",
        "(training_images, testing_images, training_labels, testing_labels) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og-0oKFaC00m"
      },
      "source": [
        "### Display few training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e35ofrxC5wL"
      },
      "source": [
        "# Show sample images from the training dataset\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(30):\n",
        "    plt.subplot(5, 6, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.imshow(training_images[i], cmap=plt.cm.gray)\n",
        "    index = np.argmax(training_labels[i])\n",
        "    color = 'red' if index == 0 else 'green' if index == 1 else 'black'\n",
        "    plt.title(lb.classes_[index], color=color)\n",
        "plt.suptitle(\"Training Data\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D45AkqTAe0V"
      },
      "source": [
        "### Perform data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywckjNDjAeQ4"
      },
      "source": [
        "# Construct the image generator for data augmentation\n",
        "print(\"[INFO] performing data augmentation...\")\n",
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.15,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "# Generate augmented data from dataset\n",
        "batch_size = 32\n",
        "train_generator = data_gen.flow(training_images, training_labels, batch_size=batch_size)\n",
        "test_generator = data_gen.flow(testing_images, testing_labels)\n",
        "\n",
        "# Plot a random augmented image with transformations\n",
        "augmented_imgs = [train_generator[0][0][0] for i in range(10)]\n",
        "plt.figure(figsize=(12, 10))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(augmented_imgs[i], cmap=plt.cm.gray)\n",
        "plt.suptitle(\"Transformations for an Image\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKLkwvSSAksM"
      },
      "source": [
        "### Define the CNN classifier network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJWvOMaXAlw2"
      },
      "source": [
        "# Perform Transfer Learning with MobileNetV2 network\n",
        "# Load the MobileNetV2 network\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "    input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Construct the head of the model to place on top of the base model\n",
        "head_model = base_model.output\n",
        "head_model = AveragePooling2D(pool_size=(7, 7))(head_model)\n",
        "head_model = Flatten(name=\"flatten\")(head_model)\n",
        "head_model = Dense(128, activation=\"relu\")(head_model)\n",
        "head_model = Dropout(0.5)(head_model)\n",
        "n_classes = len(lb.classes_)\n",
        "head_model = Dense(n_classes, activation=\"softmax\")(head_model)\n",
        "\n",
        "# Construct actual model for training\n",
        "model = Model(inputs=base_model.input, outputs=head_model)\n",
        "\n",
        "# Initialize the initial learning rate and number of epochs\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 100\n",
        "\n",
        "# Compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# Show the full model summary\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ux0Ag6A00A"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNVwKpXeA1lp"
      },
      "source": [
        "# Stop training when 99% accuracy is reached\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        accuracy = 0.99\n",
        "        EPOCHS = epoch\n",
        "        if (logs.get('accuracy') > accuracy):\n",
        "            print(\"\\n[INFO] Reached {}% accuracy, cancelling training...\".format(accuracy * 100))\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train the head of the network for 100 epochs\n",
        "print(\"[INFO] training head...\")\n",
        "hist = model.fit(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=len(training_images) // batch_size,\n",
        "    validation_data=test_generator,\n",
        "\tvalidation_steps=len(testing_images) // batch_size,\n",
        "    callbacks=[callbacks],\n",
        "\tepochs=EPOCHS)\n",
        "\n",
        "print(\"[INFO] finished training model.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jueH3Sk8BAu-"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzbaE90rBBq3"
      },
      "source": [
        "# Evaluate model using images in the testing dataset\n",
        "print(\"[INFO] evaluating network...\")\n",
        "test_loss, test_acc = model.evaluate(testing_images, testing_labels)\n",
        "model.evaluate(test_generator)\n",
        "print(\"[INFO] test accuracy:\", test_acc)\n",
        "\n",
        "# Make predictions on the testing dataset\n",
        "class_predictions = model.predict(testing_images)\n",
        "#class_predictions = model.predict(testing_images, batch_size=batch_size)\n",
        "# Find the index of the label with the largest predicted probability\n",
        "predIdxs = np.argmax(class_predictions, axis=1)\n",
        "# Get the index of the true label\n",
        "trueIdxs = np.argmax(testing_labels, axis=1)\n",
        "\n",
        "# Use SciKit-Learn to show a classification report and plot a confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Show a classification report\n",
        "print(\"[INFO] classification report:\")\n",
        "print(classification_report(testing_labels.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "# Plot a confusion matrix\n",
        "cm = confusion_matrix(trueIdxs, predIdxs)\n",
        "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(lb.classes_))\n",
        "plt.xticks(tick_marks, lb.classes_, rotation=85)\n",
        "plt.yticks(tick_marks, lb.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot random test images with their predicted labels\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(20):\n",
        "  ax = plt.subplot(4, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  # plt.subplots_adjust(wspace=0.3)\n",
        "  plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "  index = random.randint(0, len(predIdxs) - 1)\n",
        "  plt.imshow(testing_images[index], cmap=plt.cm.gray)\n",
        "\n",
        "  color = 'blue' if predIdxs[index] == trueIdxs[index] else 'red'\n",
        "  plt.xlabel(\"{} {:2.0f}% [{}]\".format(lb.classes_[predIdxs[index]],\n",
        "                                       100 * np.max(class_predictions[i]),\n",
        "                                       lb.classes_[trueIdxs[index]]), color=color)\n",
        "plt.suptitle(\"Class Predictions\")\n",
        "#plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfDxD1BEBC0-"
      },
      "source": [
        "### Plot test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTA8uKNLBI1Z"
      },
      "source": [
        "# Helper functions for plotting results\n",
        "def plot_image(predictions, true_label, img):\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions)\n",
        "    color = 'blue' if predicted_label == true_label else 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% [{}]\".format(lb.classes_[predicted_label],\n",
        "                                         100 * np.max(predictions),\n",
        "                                         lb.classes_[true_label]), color=color)\n",
        "\n",
        "def plot_value_array(predictions, true_label):\n",
        "    plt.xticks(range(len(lb.classes_)))\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    thisplot = plt.bar(range(len(lb.classes_)), predictions, color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "\n",
        "    predicted_label = np.argmax(predictions)\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')\n",
        "\n",
        "# Plot test images with their predicted and true labels\n",
        "print(\"[INFO] generating plots...\")\n",
        "num_rows = 4\n",
        "num_cols = 5\n",
        "num_images = num_rows * num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  image_plt = np.squeeze(testing_images[i])\n",
        "  true_label = np.argmax(testing_labels[i])\n",
        "  #index = random.randint(0, len(predIdxs) - 1)\n",
        "  plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
        "  plot_image(class_predictions[i], true_label, image_plt)\n",
        "  plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)\n",
        "  plot_value_array(class_predictions[i], true_label)\n",
        "plt.suptitle(\"Predictions for {} test images\".format(num_images))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjlFpu2iBXAd"
      },
      "source": [
        "### Plot Training Loss and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XAmbrdPBZtF"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "print(\"[INFO] generating training loss and accuracy plots...\")\n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "epochs_range = range(1, EPOCHS + 1)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='train_acc')\n",
        "plt.plot(epochs_range, val_acc, label='val_acc')\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='train_loss')\n",
        "plt.plot(epochs_range, val_loss, label='val_loss')\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig(\"plot _ {}_epoch{}\".format(now, EPOCHS))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs48NAbmD5NU"
      },
      "source": [
        "### Make predictions for new images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS4sCKYUD6JC"
      },
      "source": [
        "# Plot a single image with its predicted label\n",
        "def classify_image(image_path, true_label):\n",
        "    # Load the input image (224x224) and preprocess it\n",
        "    img = load_img(image_path, target_size=image_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "    img_preprocessed = np.array(img_batch, dtype=\"float32\") / 255.0\n",
        "\n",
        "    # Predict the class label for the preprocessed image\n",
        "    class_prediction = model.predict(img_preprocessed)\n",
        "    # Get the class label with the largest predicted probability\n",
        "    index = np.argmax(class_prediction, axis=1)[0]\n",
        "    label = lb.classes_[index]\n",
        "\n",
        "    print(\"This image most likely belongs to \\'{}\\' with a {:.2f} percent confidence.\"\n",
        "          .format(label, 100 * np.max(class_prediction)))\n",
        "\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plot_image(class_prediction[0], true_label, img)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plot_value_array(class_prediction[0], true_label)\n",
        "    plt.suptitle(\"Class Prediction\")\n",
        "    plt.show()\n",
        "\n",
        "label_map = {'covid': 0, 'normal': 1, 'not xray': 2}\n",
        "for image_path in image_paths:\n",
        "    label = image_path.split(os.path.sep)[-2]\n",
        "    #classify_image(image_path, label_map[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyvMbOA3BKBa"
      },
      "source": [
        "### Save weights and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0jD0pDlBK_b"
      },
      "source": [
        "# Save the trained model and weights\n",
        "print(\"[INFO] saving trained weights and model...\")\n",
        "from datetime import datetime\n",
        "now = datetime.now().strftime('%Y-%m-%d _%H-%M-%S')\n",
        "model_weights_name = \"model_weights _ {}.h5\".format(now)\n",
        "export_path_wgs = \"./\" + model_weights_name\n",
        "model.save_weights(export_path_wgs)\n",
        "print(\"[INFO] weights saved.\")\n",
        "model_file_name = \"model_classifier _ {}.h5\".format(now)\n",
        "export_path_mdl = \"./\" + model_file_name\n",
        "model.save(export_path_mdl)\n",
        "print(\"[INFO] model saved.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b2i4_HpEGqg"
      },
      "source": [
        "### Convert model to TF Lite format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9qJi25NEHbf"
      },
      "source": [
        "# Convert Keras model to TF Lite format\n",
        "print(\"[INFO] converting model to TF Lite format...\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_float_model = converter.convert()\n",
        "open(\"classifier_float_model _ {}.tflite\".format(now), \"wb\").write(tflite_float_model)\n",
        "# Show model size in KBs\n",
        "float_model_size = len(tflite_float_model) / 1024\n",
        "print('[INFO] TFLite Float model size = %dKBs.' % float_model_size)\n",
        "\n",
        "# Re-convert the model to TF Lite using quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "open(\"classifier_quant_model _ {}.tflite\".format(now), \"wb\").write(tflite_quantized_model)\n",
        "# Show model size in KBs\n",
        "quantized_model_size = len(tflite_quantized_model) / 1024\n",
        "print('[INFO] TFLite Quantized model size = %dKBs,' % quantized_model_size)\n",
        "print('which is about %d%% of the float model size.'\\\n",
        "      % (quantized_model_size * 100 / float_model_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPMug5vkENff"
      },
      "source": [
        "### Evaluate TF Lite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0hSid3kEOUd"
      },
      "source": [
        "# Evaluate the TF Lite model using images in the test dataset\n",
        "def evaluate_tflite_model(tflite_model):\n",
        "  # Initialize TFLite interpreter using the model\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "  input_tensor_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "\n",
        "  # Run predictions on every image in the test dataset\n",
        "  prediction_digits = []\n",
        "  for test_image in testing_images:\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_tensor_index, test_image)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy\n",
        "  accurate_count = 0\n",
        "  for index in range(len(prediction_digits)):\n",
        "    if prediction_digits[index] == testing_labels[index]:\n",
        "      accurate_count += 1\n",
        "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "print(\"[INFO] evaluating TF Lite models...\")\n",
        "# Evaluate the TF Lite float model\n",
        "float_accuracy = evaluate_tflite_model(tflite_float_model)\n",
        "print('[INFO] Float model accuracy = %.4f' % float_accuracy)\n",
        "\n",
        "# Evaluate the TF Lite quantized model\n",
        "quantized_accuracy = evaluate_tflite_model(tflite_quantized_model)\n",
        "print('[INFO] Quantized model accuracy = %.4f' % quantized_accuracy)\n",
        "print('[INFO] Accuracy drop = %.4f' % (float_accuracy - quantized_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzZvnVcVESdp"
      },
      "source": [
        "### Download the TF Lite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqEBmCMWEZu-"
      },
      "source": [
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "labels = ['cat', 'dog']\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write('\\n'.join(labels))\n",
        "  \n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download(tflite_float_model_file)\n",
        "  files.download('labels.txt')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}